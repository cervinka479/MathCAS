{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b82cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add project root to sys.path (works in Jupyter)\n",
    "project_root = Path.cwd().parent\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94091986",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import sys\n",
    "import torch\n",
    "import numpy as np\n",
    "import yaml\n",
    "import logging\n",
    "from pathlib import Path\n",
    "from src import architecture, dataset, trainer\n",
    "from utils import experiment, logger, metrics, modules, profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f7ba834",
   "metadata": {},
   "source": [
    "### Neural Network Architecture Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70acbdcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config.schema import ArchitectureConfig\n",
    "from src.architecture import NeuralNetwork\n",
    "\n",
    "arch_config = ArchitectureConfig(\n",
    "    in_size=9,\n",
    "    out_size=3,\n",
    "    hidden_layers=[64, 32],\n",
    "    activation=\"ReLU\",\n",
    "    use_dropout=False,\n",
    "    dropout=0.5,\n",
    "    dropout_inplace=False,\n",
    "    final_activation=None\n",
    ")\n",
    "\n",
    "model = NeuralNetwork(arch_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe09777",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print current model architecture\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "pprint(arch_config.model_dump(), sort_dicts=False)\n",
    "print()\n",
    "print(model)\n",
    "print()\n",
    "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Number of trainable parameters: {total_params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d610b9",
   "metadata": {},
   "source": [
    "### Data Loading Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16405fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config.schema import DataConfig\n",
    "from src.dataset import prepare_dataloaders\n",
    "\n",
    "data_config = DataConfig(\n",
    "    path_to_data=\"c:/Users/cervinka/cervinka/dataset_compressible_flow_60M_training_nstep180.csv\",\n",
    "    num_samples=5000,\n",
    "    batch_size=50,\n",
    "    in_cols=[\"A11\", \"A21\", \"A31\", \"A12\", \"A22\", \"A32\", \"A13\", \"A23\", \"A33\"],\n",
    "    out_cols=[\"Shear\"],\n",
    "    val_split=0.1,\n",
    "    shuffle=False,\n",
    "    sliding_window=None\n",
    ")\n",
    "\n",
    "train_loader, val_loader = prepare_dataloaders(data_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a1665f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print current data configuration\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "pprint(data_config.model_dump(), sort_dicts=False)\n",
    "print()\n",
    "def print_loader_stats(train_loader, val_loader):\n",
    "    try:\n",
    "        train_samples = len(train_loader.dataset)\n",
    "        val_samples = len(val_loader.dataset)\n",
    "    except Exception:\n",
    "        # Fallback for custom loaders\n",
    "        train_samples = sum(1 for _ in train_loader)\n",
    "        val_samples = sum(1 for _ in val_loader)\n",
    "\n",
    "    train_batches = len(train_loader)\n",
    "    val_batches = len(val_loader)\n",
    "\n",
    "    print(f\"Train samples: {train_samples}\")\n",
    "    print(f\"Validation samples: {val_samples}\")\n",
    "    print(f\"Train batches: {train_batches}\")\n",
    "    print(f\"Validation batches: {val_batches}\")\n",
    "\n",
    "    if hasattr(train_loader, 'batch_size'):\n",
    "        print(f\"Batch size: {train_loader.batch_size}\")\n",
    "\n",
    "    # Example batch shapes\n",
    "    for batch_x, batch_y in train_loader:\n",
    "        print(f\"Example train batch X shape: {batch_x.shape}\")\n",
    "        print(f\"Example train batch Y shape: {batch_y.shape}\")\n",
    "        break\n",
    "    for batch_x, batch_y in val_loader:\n",
    "        print(f\"Example val batch X shape: {batch_x.shape}\")\n",
    "        print(f\"Example val batch Y shape: {batch_y.shape}\")\n",
    "        break\n",
    "\n",
    "print_loader_stats(train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb27c842",
   "metadata": {},
   "source": [
    "### Neural Network Training Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ae848b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config.schema import TrainingConfig\n",
    "\n",
    "training_config = TrainingConfig(\n",
    "    learning_rate=0.001,\n",
    "    optimizer=\"Adam\",\n",
    "    loss_function=\"MSELoss\",\n",
    "    epochs=30,\n",
    "    early_stopping=True,\n",
    "    patience=10,\n",
    "    scheduler=\"ReduceLROnPlateau\",\n",
    "    scheduler_patience=3,\n",
    "    scheduler_factor=0.5,\n",
    "    scheduler_threshold=0.01\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1d76f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print current training configuration\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "pprint(training_config.model_dump(), sort_dicts=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba4e3d63",
   "metadata": {},
   "source": [
    "# Creating new experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57123f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set experiment name and seed\n",
    "experiment_name = \"exp1\"\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c8c1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new jupyter experiment\n",
    "\n",
    "import random\n",
    "import hashlib\n",
    "from utils.experiment import create_experiment_dir\n",
    "from utils.logger import setup_logger\n",
    "\n",
    "# Set output directory for experiments (relative to notebooks/outputs)\n",
    "output_dir = Path.cwd() / \"outputs\"\n",
    "exp_dir = create_experiment_dir(str(output_dir), experiment_name)\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "# --- Logging setup ---\n",
    "log_file = os.path.join(exp_dir, \"notebook.log\")\n",
    "logger = setup_logger(verbose=True, log_to_file=True, log_file=log_file)\n",
    "\n",
    "logger.info(f\"Experiment directory: {exp_dir}\")\n",
    "logger.info(f\"Seed: {seed}\")\n",
    "\n",
    "# --- Logging setup ---\n",
    "log_file = os.path.join(exp_dir, \"notebook.log\")\n",
    "logger = setup_logger(verbose=True, log_to_file=True, log_file=log_file)\n",
    "\n",
    "# --- Config hash for reproducibility ---\n",
    "import json\n",
    "def config_hash(*configs):\n",
    "    # Combine all config dicts and hash them\n",
    "    config_str = json.dumps([c.model_dump() for c in configs], sort_keys=True)\n",
    "    return hashlib.md5(config_str.encode(\"utf-8\")).hexdigest()\n",
    "\n",
    "hash_val = config_hash(arch_config, training_config, data_config)\n",
    "logger.info(f\"Config hash: {hash_val}\")\n",
    "\n",
    "# --- CUDA/Device info ---\n",
    "logger.info(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    logger.info(f\"CUDA device: {torch.cuda.get_device_name(0)}\")\n",
    "    cuda_version = getattr(torch.version, \"cuda\", \"N/A\")  # type: ignore\n",
    "    logger.info(f\"CUDA version: {cuda_version}\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "logger.info(f\"Using device: {device}\")\n",
    "\n",
    "# --- Model parameter count ---\n",
    "num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "logger.info(f\"Total trainable parameters: {num_params}\")\n",
    "\n",
    "# --- Log experiment and configs ---\n",
    "logger.info(f\"Experiment: {experiment_name}\")\n",
    "logger.info(f\"Model architecture:\\n{model}\")\n",
    "logger.info(f\"Training config: {training_config}\")\n",
    "logger.info(f\"Data config: {data_config}\")\n",
    "\n",
    "# --- Log dataset stats ---\n",
    "try:\n",
    "    train_samples = len(train_loader.dataset) # type: ignore\n",
    "    val_samples = len(val_loader.dataset) # type: ignore\n",
    "except Exception:\n",
    "    train_samples = sum(1 for _ in train_loader)\n",
    "    val_samples = sum(1 for _ in val_loader)\n",
    "logger.info(f\"Training samples: {train_samples} | Validation samples: {val_samples} | Batch size: {data_config.batch_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "838df967",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093a8b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the training loop #\n",
    "\n",
    "from src.trainer import train_one_epoch, validate\n",
    "from utils.modules import get_loss_function, get_optimizer, get_scheduler\n",
    "from utils.metrics import format_time\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = get_loss_function(training_config.loss_function)\n",
    "optimizer = get_optimizer(\n",
    "    training_config.optimizer,\n",
    "    model.parameters(),\n",
    "    training_config.learning_rate\n",
    ")\n",
    "\n",
    "scheduler = None\n",
    "if training_config.scheduler == \"ReduceLROnPlateau\":\n",
    "    scheduler = get_scheduler(\n",
    "        \"ReduceLROnPlateau\",\n",
    "        optimizer,\n",
    "        patience=training_config.scheduler_patience or 2,\n",
    "        factor=training_config.scheduler_factor or 0.5,\n",
    "        threshold=training_config.scheduler_threshold or 1e-4,\n",
    "        verbose=True\n",
    "    )\n",
    "\n",
    "best_val_loss = float(\"inf\")\n",
    "best_epoch = -1\n",
    "patience_counter = 0\n",
    "train_losses, val_losses, elapsed_times = [], [], []\n",
    "start_time = time.time()\n",
    "\n",
    "# Training loop\n",
    "try:\n",
    "    for epoch in range(training_config.epochs):\n",
    "\n",
    "        train_loader, val_loader = prepare_dataloaders(data_config, epoch=epoch)\n",
    "\n",
    "        train_loss = train_one_epoch(model, train_loader, criterion, optimizer, device)\n",
    "        val_loss = validate(model, val_loader, criterion, device)\n",
    "\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "        # Step the scheduler\n",
    "        if scheduler is not None:\n",
    "            scheduler.step(val_loss)\n",
    "\n",
    "        # Early stopping\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_epoch = epoch + 1\n",
    "            best_model_state = model.state_dict()\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "\n",
    "        elapsed_time = time.time() - start_time\n",
    "        elapsed_times.append(elapsed_time)\n",
    "\n",
    "        # Log epoch information\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        logger.info(\n",
    "            f\"Epoch {epoch + 1}/{training_config.epochs} | \"\n",
    "            f\"Train Loss: {train_loss:.4e} | Val Loss: {val_loss:.4e} | \"\n",
    "            f\"LR: {current_lr:.2e} | Time: {format_time(elapsed_time)}\"\n",
    "        )\n",
    "\n",
    "        # Log scheduler events (ReduceLROnPlateau)\n",
    "        if scheduler is not None and hasattr(scheduler, 'num_bad_epochs') and scheduler.num_bad_epochs == 0 and epoch > 0:\n",
    "            logger.info(f\"Learning rate reduced to {current_lr:.2e}\")\n",
    "\n",
    "        if training_config.early_stopping and patience_counter >= training_config.patience:\n",
    "                    logger.info(f\"Early stopping at epoch {epoch + 1}\")\n",
    "                    break\n",
    "        \n",
    "    total_time = time.time() - start_time\n",
    "    logger.info(\"Training complete.\")\n",
    "    logger.info(f\"Best model at epoch {best_epoch} | Val Loss: {best_val_loss:.4e}\")\n",
    "    logger.info(f\"Total training time: {format_time(total_time)}\")\n",
    "\n",
    "except Exception as e:\n",
    "    import traceback\n",
    "    logger.error(\"Exception during training:\\n\" + traceback.format_exc())\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad773d2",
   "metadata": {},
   "source": [
    "### Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0530cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save best model #\n",
    "\n",
    "best_model_path = os.path.join(exp_dir, \"best_model.pt\")\n",
    "torch.save(best_model_state, best_model_path)\n",
    "print(f\"Best model saved to {best_model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20e53af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save training history #\n",
    "\n",
    "history_path = os.path.join(exp_dir, \"training_history.pt\")\n",
    "torch.save({\n",
    "    \"optimizer_state\": optimizer.state_dict(),\n",
    "    \"train_losses\": train_losses,\n",
    "    \"val_losses\": val_losses,\n",
    "    \"best_epoch\": best_epoch,\n",
    "    \"best_val_loss\": best_val_loss,\n",
    "}, history_path)\n",
    "print(f\"Training history saved to {history_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "926d72f2",
   "metadata": {},
   "source": [
    "### Additional training (WIP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5960b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload best model weights\n",
    "model.load_state_dict(torch.load(best_model_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28172d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload optimizer state (if you want to preserve momentum, etc.)\n",
    "optimizer.load_state_dict(torch.load(history_path)[\"optimizer_state\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fab3686",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.11.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
